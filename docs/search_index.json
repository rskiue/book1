[["index.html", "IPW chapter: 1 book_title 1.1 書籍作成方法", " IPW author_name 2022-05-25 chapter: 1 book_title このRm。す。 1.1 書籍作成方法 1.1.1 必要なパッケージ,環境など Kください。 http://ipafont.ipa.go.jp/ また。 1.1.2 Download 1.1.2.1 種類 gitboo "],["01-title1.html", "chapter: 2 メモ", " chapter: 2 メモ HTML（Gitbook）形式でもPDF形式でも日本語で出力すること。（ggplotなど含む） ill-identified氏のRmd-jaを使うか。KUNISATOさんらのパッケージ（心理学研究）を使うか。 前者はいろいろとカスタマイズがされている。ドキュメントにう記載の一式を読み込むと必要なファイルがダウンロードできる。 エラーメッセージの文字化けをなくしたい。 パッケージ導入や環境構築、分析に再現性を持たせること。 適当に編集してください。 "],["02-title2.html", "chapter: 3 章のタイトル2 3.1 節見出し1 3.2 節見出し2", " chapter: 3 章のタイトル2 進捗どうですか? 3.1 節見出し1 ほげほげ iris %&gt;% tibble() %&gt;% ggplot(aes(x=Sepal.Length,y=Sepal.Width))+ geom_point()+ labs(x=&quot;ほげほげ&quot;,y=&quot;ふがふが&quot;) 3.2 節見出し2 ふがふが "],["03-method.html", "chapter: 4 Methods 4.1 GMM", " chapter: 4 Methods ここではGMMについて見ていく。 library(tidyverse) library(ggdag) ## ## 次のパッケージを付け加えます: &#39;ggdag&#39; ## 以下のオブジェクトは &#39;package:stats&#39; からマスクされています: ## ## filter library(dagitty) 内生変数一つに対して操作変数が例えば3つある時に、それを全部使って効率的に推定できる。 tidy_dag_2 &lt;- ggdag::dagify( Y ~ D + X + U, D ~ U+Z1+Z2+Z3, exposure = &quot;D&quot;, # 処置変数（暴露 [exposure]） を指定 outcome = &quot;Y&quot; , # 結果変数を指定 latent = &quot;U&quot;, # 未観測（潜在[latent]）変数を指定 coords = list(x = c(Z3 = 0, X=2, Z2 = 0, D = 1, Y = 3, U = 2,Z1=0), y = c(Z3 = 0.5,X=-0.5,Z2 = -0.5, D = 0, Y = 0, U = 1,Z1=0)) ) %&gt;% ggdag::tidy_dagitty() ggdag::ggdag(tidy_dag_2,stylized = TRUE) + ggdag::theme_dag_blank() a u&lt;-rnorm(10000) z1&lt;-rnorm(10000) z2&lt;-rnorm(10000) z3&lt;-rnorm(10000) x&lt;-1+rnorm(10000) d&lt;-1+3*u+0.5*z1+0.7*z2+z3+rnorm(10000) y&lt;-0.5*d+2*x+0.8*u+rnorm(10000) dt&lt;-tibble(u,x,z1,z2,z3,d,y) lm(y~d,data=dt) %&gt;%summary #biased ## ## Call: ## lm(formula = y ~ d, data = dt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.9630 -1.5692 0.0072 1.5380 8.3469 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.809644 0.023413 77.29 &lt;2e-16 *** ## d 0.705483 0.006581 107.19 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.257 on 9998 degrees of freedom ## Multiple R-squared: 0.5347, Adjusted R-squared: 0.5347 ## F-statistic: 1.149e+04 on 1 and 9998 DF, p-value: &lt; 2.2e-16 lm(y~d+z1,data=dt) %&gt;%summary #biased ## ## Call: ## lm(formula = y ~ d + z1, data = dt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.8231 -1.5692 0.0027 1.5286 8.4391 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.807027 0.023410 77.191 &lt; 2e-16 *** ## d 0.708662 0.006635 106.804 &lt; 2e-16 *** ## z1 -0.083471 0.022943 -3.638 0.000276 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.255 on 9997 degrees of freedom ## Multiple R-squared: 0.5353, Adjusted R-squared: 0.5353 ## F-statistic: 5759 on 2 and 9997 DF, p-value: &lt; 2.2e-16 #install.packages(&quot;estimatr&quot;) library(estimatr) iv_robust(y ~ d | z1, data = dt, se_type = &quot;classical&quot;) %&gt;%summary ## ## Call: ## iv_robust(formula = y ~ d | z1, data = dt, se_type = &quot;classical&quot;) ## ## Standard error type: classical ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF ## (Intercept) 1.9803 0.05438 36.42 9.450e-273 1.8737 2.0869 9998 ## d 0.5254 0.05181 10.14 4.779e-24 0.4238 0.6269 9998 ## ## Multiple R-squared: 0.4999 , Adjusted R-squared: 0.4998 ## F-statistic: 102.8 on 1 and 9998 DF, p-value: &lt; 2.2e-16 2SLSで推定する場合は以下。 \\[ \\boldsymbol{\\hat{D}=Z(Z&#39;Z)^{-1}Z&#39;D}\\\\ \\boldsymbol{\\beta^{2SLS}=(\\hat{D}&#39;\\hat{D})^{-1}\\hat{D}&#39;Y}\\\\ =\\boldsymbol{(D&#39;Z(Z&#39;Z)^{-1}ZD&#39;)^{-1} D&#39;Z(Z&#39;Z)^{-1}Z&#39;Y} \\] Zの数とDの数が同じ場合は、ZD’が正方行列となり(Z’D)^{-1}が定義できるので \\[ =\\boldsymbol{(D&#39;Z(Z&#39;Z)^{-1}ZD&#39;)^{-1} D&#39;Z(Z&#39;Z)^{-1}Z&#39;D(Z&#39;D)^{-1}Z&#39;Y}\\\\ =\\boldsymbol{(Z&#39;D)^{-1}Z&#39;Y} \\] lm(d~z1) %&gt;% predict() %&gt;% tibble(yhat=.,dt) %&gt;% lm(y~yhat,data=.) ## ## Call: ## lm(formula = y ~ yhat, data = .) ## ## Coefficients: ## (Intercept) yhat ## 1.9803 0.5254 操作変数法で推定する場合は以下。ただ内生変数の数が１つ、操作変数の数が１つの時も、\\(\\boldsymbol{Z=(1\\;Z),D=(1\\;D)}\\)であることに注意して、 \\[ \\boldsymbol{\\beta^{IV}=(Z&#39;D)^{-1}Z&#39;Y}\\\\ \\begin{pmatrix}\\beta_0\\\\\\beta_1\\end{pmatrix} =\\begin{pmatrix}N&amp;\\sum{D}\\\\\\sum{Z}&amp;\\sum{ZD}\\end{pmatrix}^{-1} \\begin{pmatrix}\\sum{Y}\\\\\\sum{ZY}\\end{pmatrix}\\\\ \\beta_1=\\frac{N\\sum{ZY}-\\sum{Z}\\sum{Y}}{N\\sum{ZD}-\\sum{Z}\\sum{D}}=\\frac{Cov(Z,Y)}{Cov(Z,D)} \\] z1%*%y/(z1%*%d) #これは正しくない。 ## [,1] ## [1,] 0.5460973 cov(y, z1) / cov(d, z1) #こっちが正しい ## [1] 0.525372 4.1 GMM 例として、操作変数が３つ、内生変数が１つの場合を考える。 \\(\\boldsymbol{Z=(1\\;Z_1\\;Z_2\\;Z_3)}\\)とすると、\\(E\\boldsymbol{(Z&#39;(Y-X\\beta))=0}\\)の4つの直行条件ができる。 一方でbetaは2次元なので、すべて0となるようにbetaを決めることはできないため、それらの二乗和が最小になるようにbetaを決める。 すなわち、\\(\\frac{1}{n}\\sum Z_i(Y_i-X_i\\beta)\\)の二乗が小さくなるように決める。この4つの各成分の二乗和が最小となるようbetaを決める。これはZYをZXにOLSすることと同じなので、 \\(\\boldsymbol{\\beta=(X&#39;ZZ&#39;X)^{-1}X’ZZ&#39;Y}\\)となる。 ここで、なんか良い感じにスケールをそろえるためにウェイトWをかける。 \\(\\boldsymbol{\\beta=(X&#39;Z\\hat{W}Z&#39;X)^{-1}X’Z\\hat{W}Z&#39;Y}\\)となる。 d_m&lt;-tibble(rep(1,10000),d) %&gt;% as.matrix() z_m&lt;-tibble(rep(1,10000),z1,z2,z3)%&gt;% as.matrix() solve(t(d_m)%*%z_m%*%t(z_m)%*%d_m)%*% t(d_m)%*%z_m%*%t(z_m)%*%y ## [,1] ## rep(1, 10000) 2.0020306 ## d 0.5024534 "],["04-literature.html", "chapter: 5 メモ 5.1 Bookdown関連 5.2 Docker関連", " chapter: 5 メモ 5.1 Bookdown関連 Bookdownをweb（github.io）上で掲載する。 とりあえずbookdown形式のファイルを作る。Bookdownの作り方は、作成者のYihui氏のチュートリアルが参考になる。 チュートリアルに記載されている通り、デモ用のファイルを一式ダウンロードするのが早い。 基本的にbookdownパッケージをRstudioでインストール、tinytexをインストールした上で、デモ用のRprojファイルを開き、index.Rmdファイルを開いてBuild BookするだけでOK。 ただし、webで公開することを念頭に置く場合は、_bookdown.ymlで、output_dir: \"docs\" を記載する必要がある（参考情報のYihui氏のページ参照）。これによって、Rmd達から出力されるhtmlファイルがdocsフォルダに格納されることになる。 これをpushする。 Github PagesのSettingsでSourceをdocsにする。これにより、デフォルトだとレポジトリ直下に置かれたindex.htmlファイルをもとにページが作られるが、docsフォルダにあるhtmlをベースに作ってくれよと指定することになる。 5.2 Docker関連 Dockerイメージから開発環境を引っ張ってくれる。 日本語ではrockerjp/verseがよさそう。 モチベーション Rstudio Serverで作業することになるが、もってきた環境を使って、Rstudio Desktopで作業できないのか？ もってきた環境をベースに、自分でライブラリとかを追加したい場合はどうしたら良いか。またそれを新たに配布したい。 ベースとしては既存のものを活用して、それをカスタマイズしたいということ。 5.2.1 参考情報 参考 レポジトリ名を(username).github.ioにすると、同名のURLのGithub Pagesとなる。レポジトリ名をその他の名前（aaa）とすると、(username).github.io/aaaでbookdownページが作成される。 BookdownのGithub Pagesでの公開は、Yihui氏のページが参考になる。同ページではJekyllを無効化するためのファイルを作れなどと記載があるが、なくても何とかなった。 R markdown cookbook（翻訳版）も参考になる。 "],["heterogeneous-treatment-effect-1.html", "chapter: 6 HTE I: Binary treatment 6.1 Pre-specified hypotheses 6.2 Data-driven hypotheses 6.3 Further reading", " chapter: 6 HTE I: Binary treatment Source RMD file: link 前章では、母集団全員に対する平均処置効果について学んできた。しかし、平均効果を見るだけでは、ある個々人がどのように処置に対して反応したかという重要な事実を十分に把握することができない。そこでこの章では、以下で定義される条件付き因果効果（CATE）について見ていく。 In the previous chapter, we learned how to estimate the effect of a binary treatment averaged over the entire population. However, the average may obscure important details about how different individuals react to the treatment. In this chapter, we will learn how to estimate the conditional average treatment effect (CATE), \\[\\begin{equation} \\tag{6.1} \\tau(x) := \\mathop{\\mathrm{E}}[Y_i(1) - Y_i(0) | X_i = x] \\end{equation}\\] これは、「localized」されたバージョンの平均処置効果であり、観察可能な変数で条件付けされたものである。 (6.1) は一般化しすぎていて利用しにくいことがしばしばあり、特に共変量が高次元な場合には顕著である。強いモデリングの仮定をおかない限りは、信頼のおける推定は難しく、推定後に結果を意味のある形で要約することも難しい。そこで代わりに、単純なグループごとの処置効果の平均値を推定することとする。 which is a “localized” version of the average treatment effect conditional on a vector of observable characteristics. It’s often the case that (6.1) is too general to be immediately useful, especially when the observable covariates are high-dimensional. It can be hard to estimate reliably without making strong modeling assumptions, and hard to summarize in a useful manner after estimation. In such situations, we will instead try to estimate treatment effect averages for simpler groups \\[\\begin{equation} \\tag{6.2} \\mathop{\\mathrm{E}}[Y_i(1) - Y_i(0) | G_i = g], \\end{equation}\\] 以下では、あらかじめ定義したサブグループ別の処置効果について推定するのと、サブグループを見つける方法（Data drivenで）を見ていく。 where \\(G_i\\) indexes subgroups of interest. Below you’ll learn how to estimate and test hypotheses about pre-defined subgroups, and also how to discover subgroups of interest from the data. In this tutorial, you will learn how to use estimates of (6.1) to suggest relevant subgroups \\(G_i\\) (and in the next chapters you will find out other uses of (6.1) in policy learning and evaluation). GSSのデータを使用する。RCTデータだが、以下で見ていく手法は、Unconfoundednessが成り立っている限りは観察データにも利用できる。 We’ll continue using the abridged version of the General Social Survey (GSS) (Smith, 2016) dataset that was introduced in the previous chapter. In this dataset, individuals were sent to treatment or control with equal probability, so we are in a randomized setting. However, many of the techniques and code shown below should also work in an observational setting provided that unconfoundedness and overlap are satisfied (these assumptions were defined in the previous chapter). # pacmanでのインストールに変更した # causalTreeはCRANにないのでGithubよりダウンロード if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) pacman::p_load(tidyverse, grf, rpart, glmnet, splines, MASS, lmtest, sandwich, devtools, reshape2) if (!require(&quot;causalTree&quot;)) devtools::install_github(&#39;susanathey/causalTree&#39;) As with other chapters in this tutorial, the code below should still work by replacing the next snippet of code with a different dataset, provided that you update the key variables treatment, outcome, and covariates below. Also, please make sure to read the comments as they may be subtle differences depending on whether your dataset was created in a randomized or observational setting. # Read in data data &lt;- read.csv(&quot;https://docs.google.com/uc?id=1kSxrVci_EUcSr_Lg1JKk1l7Xd5I9zfRC&amp;export=download&quot;) n &lt;- nrow(data) # Treatment: does the the gov&#39;t spend too much on &quot;welfare&quot; (1) or &quot;assistance to the poor&quot; (0) treatment &lt;- &quot;w&quot; # Outcome: 1 for &#39;yes&#39;, 0 for &#39;no&#39; outcome &lt;- &quot;y&quot; # Additional covariates covariates &lt;- c(&quot;age&quot;, &quot;polviews&quot;, &quot;income&quot;, &quot;educ&quot;, &quot;marital&quot;, &quot;sex&quot;) データの形状 data %&gt;% summary() ## X y w age ## Min. : 1 Min. :0.0000 Min. :0.0000 Min. :18.0 ## 1st Qu.: 8276 1st Qu.:0.0000 1st Qu.:0.0000 1st Qu.:32.0 ## Median :16649 Median :0.0000 Median :1.0000 Median :43.0 ## Mean :17552 Mean :0.2543 Mean :0.5345 Mean :45.3 ## 3rd Qu.:28017 3rd Qu.:1.0000 3rd Qu.:1.0000 3rd Qu.:57.0 ## Max. :36501 Max. :1.0000 Max. :1.0000 Max. :89.0 ## polviews income educ marital sex ## Min. :1.000 Min. : 1.0 Min. : 0.00 Min. :1.0 Min. :1.000 ## 1st Qu.:3.000 1st Qu.:10.0 1st Qu.:12.00 1st Qu.:1.0 1st Qu.:1.000 ## Median :4.000 Median :12.0 Median :13.00 Median :1.0 Median :2.000 ## Mean :4.107 Mean :10.6 Mean :13.29 Mean :2.4 Mean :1.548 ## 3rd Qu.:5.000 3rd Qu.:12.0 3rd Qu.:16.00 3rd Qu.:4.0 3rd Qu.:2.000 ## Max. :7.000 Max. :12.0 Max. :20.00 Max. :5.0 Max. :2.000 6.1 Pre-specified hypotheses ここではデータを見る前にグループは決まっていた(pre-specified)と考える。単に処置とグループの交差項を入れておけば良い。 We will begin by learning how to test pre-specified null hypotheses of the form \\[ H_{0}: \\mathop{\\mathrm{E}}[Y(1) - Y(0) | G_i = 1] = \\mathop{\\mathrm{E}}[Y(1) - Y(0) | G_i = 0]. \\] That is, that the treatment effect is the same regardless of membership to some group \\(G_i\\). Importantly, for now we’ll assume that the group \\(G_i\\) was pre-specified – it was decided before looking at the data. In a randomized setting, if the both the treatment \\(W_i\\) and group membership \\(G_i\\) are binary, we can write \\[ \\mathop{\\mathrm{E}}[Y_i(W_i)|G_i] = \\mathop{\\mathrm{E}}[Y_i|W_i, G_i] = \\beta_0 + \\beta_w W_i + \\beta_g G_i + \\beta_{wg} W_i G_i \\] When \\(W_i\\) and \\(G_i\\) are binary, this decomposition is true without loss of generality. Why? This allows us to write the average effects of \\(W_i\\) and \\(G_i\\) on \\(Y_i\\) as \\[ \\mathop{\\mathrm{E}}[Y(1) | G_i=1] = \\beta_0 + \\beta_w W_i + \\beta_g G_i + \\beta_{wg} W_i G_i,\\\\ \\mathop{\\mathrm{E}}[Y(1) | G_i=0] = \\beta_0 + \\beta_w W_i, \\\\ \\mathop{\\mathrm{E}}[Y(0) | G_i=1] = \\beta_0 + \\beta_g G_i, \\\\ \\mathop{\\mathrm{E}}[Y(0) | G_i=0] = \\beta_0. \\] 政治的志向が4未満をconservative、4以上をliveralとするバイナリ変数を新たに作る。 処置Wとの交差項を見ることで政治志向による処置効果の違いを見ることができる。 Rewriting the null hypothesis (??) in terms of the decomposition (??), we see that it boils down to a test about the coefficient in the interaction: \\(\\beta_{xw} = 0\\). Here’s an example that tests whether the treatment effect is the same for “conservative” (polviews &lt; 4) and “liberal” (polviews \\(\\geq\\) 4) individuals. # Only valid in randomized settings # Suppose this his group was defined prior to collecting the data data$conservative &lt;- factor(data$polviews &lt; 4) # a binary group group &lt;- &#39;conservative&#39; # Recall from last chapter -- this is equivalent to running a t-test fmla &lt;- formula(paste(outcome, &#39; ~ &#39;, treatment, &#39;*&#39;, group)) ols &lt;- lm(fmla, data=data) coeftest(ols, vcov=vcovHC(ols, type=&#39;HC2&#39;)) ## ## t test of coefficients: ## ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.4836473 0.0050842 95.127 &lt; 2.2e-16 *** ## w -0.3789182 0.0058604 -64.657 &lt; 2.2e-16 *** ## conservativeTRUE -0.1590214 0.0092479 -17.195 &lt; 2.2e-16 *** ## w:conservativeTRUE 0.1160034 0.0103710 11.185 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Interpret the results above. The coefficient \\(\\beta_{xw}\\) is denoted by w:conservativeTRUE. Can we detect a difference in treatment effect for conservative vs liberal individuals? For whom is the effect larger? 複数のグループがあるときには、複数の仮説検定を行う必要がある。その場合はBonferroniの補正を行う必要がある。（少々保守的すぎるが）。補正はRのbaseに入っているp.adjustコマンドで出来る。 以下のコードでは、polyviews=1と比較して、全部の政治的志向ごとに異なるという仮説のもとで検定を実施し、補正を行う。 Sometimes there are many subgroups, leading to multiple hypotheses such as \\[ H_0: \\mathop{\\mathrm{E}}[Y(1) - Y(0) \\ | \\ G_i = 1] = \\mathop{\\mathrm{E}}[Y(1) - Y(0) \\ | \\ G_i = g] \\qquad \\text{for many values of }g. \\] In that case, we need to correct for the fact that we are testing for multiple hypotheses, or we will end up with many false positives. The Bonferroni correction (wiki) is a common method for dealing with multiple hypothesis testing, though it is often too conservative to be useful. It is available via the function p.adjust from base R. The next snippet of code tests whether the treatment effect at each level of polviews is different from the treatment effect from polviews equals one. # Only valid in randomized setting. # Example: these groups must be defined prior to collecting the data. group &lt;- &#39;polviews&#39; # Linear regression. fmla &lt;- formula(paste(outcome, &#39; ~ &#39;, treatment, &#39;*&#39;, &#39;factor(&#39;, group, &#39;)&#39;)) ols &lt;- lm(fmla, data=data) ols.res &lt;- coeftest(ols, vcov=vcovHC(ols, type=&#39;HC2&#39;)) # Retrieve the interaction coefficients interact &lt;- which(sapply(names(coef(ols)), function(x) grepl(&quot;w:&quot;, x))) # Retrieve unadjusted p-values and unadj.p.value &lt;- ols.res[interact, 4] adj.p.value &lt;- p.adjust(unadj.p.value, method=&#39;bonferroni&#39;) data.frame(estimate=coef(ols)[interact], std.err=ols.res[interact,2], unadj.p.value, adj.p.value) ## estimate std.err unadj.p.value adj.p.value ## w:factor(polviews)2 -0.02424199 0.02733714 3.752056e-01 1.000000e+00 ## w:factor(polviews)3 -0.05962335 0.02735735 2.930808e-02 1.758485e-01 ## w:factor(polviews)4 -0.13461439 0.02534022 1.090684e-07 6.544105e-07 ## w:factor(polviews)5 -0.16491540 0.02713505 1.235505e-09 7.413027e-09 ## w:factor(polviews)6 -0.18007875 0.02751422 6.052625e-11 3.631575e-10 ## w:factor(polviews)7 -0.18618443 0.03870554 1.514861e-06 9.089164e-06 Romano-Wolfの補正というのもある。ブートストラップベースの手法で、最低限の仮定が用いられるため、こちらのほうが好まれる。 Another option is to use the Romano-Wolf correction, based on Romano and Wolf (2005, Econometrica). This bootstrap-based procedure takes into account the underlying dependence structure of the test statistics in a way that improves power. The Romano-Wolf procedure is correct under minimal assumptions, and should be favored over Bonferroni in general. # Auxiliary function to computes adjusted p-values # following the Romano-Wolf method. # For a reference, see http://ftp.iza.org/dp12845.pdf page 8 # t.orig: vector of t-statistics from original model # t.boot: matrix of t-statistics from bootstrapped models romano_wolf_correction &lt;- function(t.orig, t.boot) { abs.t.orig &lt;- abs(t.orig) abs.t.boot &lt;- abs(t.boot) abs.t.sorted &lt;- sort(abs.t.orig, decreasing = TRUE) max.order &lt;- order(abs.t.orig, decreasing = TRUE) rev.order &lt;- order(max.order) M &lt;- nrow(t.boot) S &lt;- ncol(t.boot) p.adj &lt;- rep(0, S) p.adj[1] &lt;- mean(apply(abs.t.boot, 1, max) &gt; abs.t.sorted[1]) for (s in seq(2, S)) { cur.index &lt;- max.order[s:S] p.init &lt;- mean(apply(abs.t.boot[, cur.index, drop=FALSE], 1, max) &gt; abs.t.sorted[s]) p.adj[s] &lt;- max(p.init, p.adj[s-1]) } p.adj[rev.order] } # Computes adjusted p-values for linear regression (lm) models. # model: object of lm class (i.e., a linear reg model) # indices: vector of integers for the coefficients that will be tested # cov.type: type of standard error (to be passed to sandwich::vcovHC) # num.boot: number of null bootstrap samples. Increase to stabilize across runs. # Note: results are probabilitistic and may change slightly at every run. # # Adapted from the p_adjust from from the hdm package, written by Philipp Bach. # https://github.com/PhilippBach/hdm_prev/blob/master/R/p_adjust.R summary_rw_lm &lt;- function(model, indices=NULL, cov.type=&quot;HC2&quot;, num.boot=10000) { if (is.null(indices)) { indices &lt;- 1:nrow(coef(summary(model))) } # Grab the original t values. summary &lt;- coef(summary(model))[indices,,drop=FALSE] t.orig &lt;- summary[, &quot;t value&quot;] # Null resampling. # This is a trick to speed up bootstrapping linear models. # Here, we don&#39;t really need to re-fit linear regressions, which would be a bit slow. # We know that betahat ~ N(beta, Sigma), and we have an estimate Sigmahat. # So we can approximate &quot;null t-values&quot; by # - Draw beta.boot ~ N(0, Sigma-hat) --- note the 0 here, this is what makes it a *null* t-value. # - Compute t.boot = beta.boot / sqrt(diag(Sigma.hat)) Sigma.hat &lt;- vcovHC(model, type=cov.type)[indices, indices] se.orig &lt;- sqrt(diag(Sigma.hat)) num.coef &lt;- length(se.orig) beta.boot &lt;- mvrnorm(n=num.boot, mu=rep(0, num.coef), Sigma=Sigma.hat) t.boot &lt;- sweep(beta.boot, 2, se.orig, &quot;/&quot;) p.adj &lt;- romano_wolf_correction(t.orig, t.boot) result &lt;- cbind(summary[,c(1,2,4),drop=F], p.adj) colnames(result) &lt;- c(&#39;Estimate&#39;, &#39;Std. Error&#39;, &#39;Orig. p-value&#39;, &#39;Adj. p-value&#39;) result } # This linear regression is only valid in a randomized setting. fmla &lt;- formula(paste(outcome, &#39; ~ &#39;, treatment, &#39;*&#39;, &#39;factor(&#39;, group, &#39;)&#39;)) ols &lt;- lm(fmla, data=data) interact &lt;- which(sapply(names(coef(ols)), function(x) grepl(paste0(treatment, &quot;:&quot;), x))) # Applying the romano-wolf correction. summary_rw_lm(ols, indices=interact) ## Estimate Std. Error Orig. p-value Adj. p-value ## w:factor(polviews)2 -0.02424199 0.03034779 4.244098e-01 0.4271 ## w:factor(polviews)3 -0.05962335 0.03015010 4.798896e-02 0.0768 ## w:factor(polviews)4 -0.13461439 0.02822807 1.862258e-06 0.0000 ## w:factor(polviews)5 -0.16491540 0.02957511 2.481093e-08 0.0000 ## w:factor(polviews)6 -0.18007875 0.02966030 1.284150e-09 0.0000 ## w:factor(polviews)7 -0.18618443 0.03790379 9.063658e-07 0.0000 Compare the adjusted p-values under Romano-Wolf with those obtained via Bonferroni above. Bonferroni補正とRomano-Wolfの補正は、familywise error rate (FWER)をコントロールする。これは、真である帰無仮説を一つでも棄却してしま確率である。（メモ：真である帰無仮説を誤って棄却してしまう確率＝Type I error＝αをコントロールする）。言い換えると、有意水準αのもと、1-αの確率で全くFalseDiscoveryしないで済むことになる。しかし、仮説検定の数が増えると、この基準は強すぎて真の効果を見落としてしまいかねない。 そこで代わりに、false discovery rate (FDR)をコントロールする補正が使われることもある。これは、棄却されたすべての帰無仮説のうちの実際には真であった帰無仮説の割合の期待値を表している。FDRはBenjamini-Hochberg の手法で補正でき、base R では p.adjust(..., method=\"BH\").コマンドで実装できる。 以下ではFWERによる調整で基本的に進めるが、FDRによる調整も有用であり、特に検討中の仮説の数が非常に多い探索的な分析においては、有用であることを覚えておきたい。 The Bonferroni and Romano-Wolf methods control the familywise error rate (FWER), which is the (asymptotic) probability of rejecting even one true null hypothesis. In other words, for a significance level \\(\\alpha\\), they guarantee that with probability \\(1 - \\alpha\\) we will make zero false discoveries. However, when the number of hypotheses being tested is very large, this criterion may be so stringent that it prevents us from being able to detect real effects. Instead, there exist alternative procedures that control the (asymptotic) false discovery rate (FDR), defined as the expected proportion of true null hypotheses rejected among all hypotheses rejected. One such procedure is the Benjamini-Hochberg procedure, which is available in base R via p.adjust(..., method=\"BH\"). For what remains we’ll stick with FWER control, but keep in mind that FDR control can also useful in exploratory analyses or settings in which there’s a very large number of hypotheses under consideration. 前章と同様に、unconfoundednessとoverlapのもとで観察データを扱う場合には、AIPWスコア \\(\\widehat{\\Gamma}_i\\) を生のアウトカム \\(Y_i\\)の代わりに使うこともできる。以下のコードでは、grf パッケージの causal_forest を使ってAIPWスコアを構築する。 （メモ：観察データを使う場合、処置が観察可能なデータで説明できるのであれば、属性による処置効果の違いは交差項を入れることで対応できない。したがって、causal forest関数を使って、アウトカムモデルと処置の予測モデルを作ることで、AIPW＝Doubly Robustを作るということ。） As in the previous chapter, when working with observational data under unconfoundedness and overlap, one can use AIPW scores \\(\\widehat{\\Gamma}_i\\) in place of the raw outcomes \\(Y_i\\). In the next snippet, we construct AIPW scores using the causal_forest function from the grf package. # Valid in randomized settings and observational settings with unconfoundedness+overlap. # Preparing data to fit a causal forest fmla &lt;- formula(paste0(&quot;~ 0 +&quot;, paste0(covariates, collapse=&quot;+&quot;))) XX &lt;- model.matrix(fmla, data) W &lt;- data[,treatment] Y &lt;- data[,outcome] # Comment or uncomment as appropriate. # Randomized setting with known and fixed probabilities (here: 0.5). forest.tau &lt;- causal_forest(XX, Y, W, W.hat=.5) # Observational setting with unconf + overlap, unknown assignment probs. forest.tau &lt;- causal_forest(XX, Y, W) # Get forest predictions. # eは傾向スコアの推定値 tau.hat &lt;- predict(forest.tau)$predictions m.hat &lt;- forest.tau$Y.hat # E[Y|X] estimates e.hat &lt;- forest.tau$W.hat # e(X) := E[W|X] estimates (or known quantity) tau.hat &lt;- forest.tau$predictions # tau(X) estimates # Predicting mu.hat(X[i], 1) and mu.hat(X[i], 0) for obs in held-out sample # Note: to understand this, read equations 6-8 in this vignette # https://grf-labs.github.io/grf/articles/muhats.html # muはアウトカムモデル。Y-e*tau mu(X,w) # Held out sampleを切り出してなくない？ mu.hat.0 &lt;- m.hat - e.hat * tau.hat # E[Y|X,W=0] = E[Y|X] - e(X)*tau(X) mu.hat.1 &lt;- m.hat + (1 - e.hat) * tau.hat # E[Y|X,W=1] = E[Y|X] + (1 - e(X))*tau(X) # Compute AIPW scores aipw.scores &lt;- tau.hat + W / e.hat * (Y - mu.hat.1) - (1 - W) / (1 - e.hat) * (Y - mu.hat.0) # Estimate average treatment effect conditional on group membership fmla &lt;- formula(paste0(&#39;aipw.scores ~ factor(&#39;, group, &#39;)&#39;)) ols &lt;- lm(fmla, data=transform(data, aipw.scores=aipw.scores)) ols.res &lt;- coeftest(ols, vcov = vcovHC(ols, &quot;HC2&quot;)) indices &lt;- which(names(coef(ols.res)) != &#39;(Intercept)&#39;) summary_rw_lm(ols, indices=indices) ## Estimate Std. Error Orig. p-value Adj. p-value ## factor(polviews)2 -0.02731358 0.03214989 3.955714e-01 0.3984 ## factor(polviews)3 -0.07240373 0.03194569 2.343048e-02 0.0362 ## factor(polviews)4 -0.13998995 0.02992254 2.904263e-06 0.0001 ## factor(polviews)5 -0.17606994 0.03134611 1.961449e-08 0.0000 ## factor(polviews)6 -0.18089630 0.03143628 8.784603e-09 0.0000 ## factor(polviews)7 -0.20001443 0.04013912 6.296079e-07 0.0000 ほかのノンパラメトリック手法でAIPWスコアを作ることもできる。ここでは、glmnet と splines関数によって柔軟な一般化線形モデルを使った場合の方法をいかに示す。 One can also construct AIPW scores using any other nonparametric method. Here’s how to do it by fitting flexible generalized linear models glmnet and splines. # Valid randomized data and observational data with unconfoundedness+overlap. # Note: read the comments below carefully. # In randomized settings, do not estimate forest.e and e.hat; use known assignment probs. # forest云々は記載ミスか。 # bs はsplineパッケージに入っているノンパラ関数 fmla.xw &lt;- formula(paste0(&quot;~&quot;, paste0(&quot;bs(&quot;, covariates, &quot;, df=3, degree=3) *&quot;, treatment, collapse=&quot;+&quot;))) fmla.x &lt;- formula(paste0(&quot;~&quot;, paste0(&quot;bs(&quot;, covariates, &quot;, df=3, degree=3)&quot;, collapse=&quot;+&quot;))) XW &lt;- model.matrix(fmla.xw, data) XX &lt;- model.matrix(fmla.x, data) Y &lt;- data[,outcome] n.folds &lt;- 5 indices &lt;- split(seq(n), sort(seq(n) %% n.folds)) aipw.scores &lt;- lapply(indices, function(idx) { # Fitting the outcome model model.m &lt;- cv.glmnet(XW[-idx,], Y[-idx]) # Predict outcome E[Y|X,W=w] for w in {0, 1} data.0 &lt;- data data.0[,treatment] &lt;- 0 XW0 &lt;- model.matrix(fmla.xw, data.0) mu.hat.0 &lt;- predict(model.m, XW0, s=&quot;lambda.min&quot;)[idx,] data.1 &lt;- data data.1[,treatment] &lt;- 1 XW1 &lt;- model.matrix(fmla.xw, data.1) mu.hat.1 &lt;- predict(model.m, XW1, s=&quot;lambda.min&quot;)[idx,] # Fitting the propensity score model # Comment / uncomment the lines below as appropriate. # OBSERVATIONAL SETTING (with unconfoundedness+overlap): # model.e &lt;- cv.glmnet(XX[-idx,], W[-idx], family=&quot;binomial&quot;) # e.hat &lt;- predict(model.e, XX[idx,], s=&quot;lambda.min&quot;, type=&quot;response&quot;) # RANDOMIZED SETTING e.hat &lt;- rep(0.5, length(idx)) # Compute CATE estimates tau.hat &lt;- mu.hat.1 - mu.hat.0 # Compute AIPW scores aipw.scores &lt;- (tau.hat + W[idx] / e.hat * (Y[idx] - mu.hat.1) - (1 - W[idx]) / (1 - e.hat) * (Y[idx] - mu.hat.0)) aipw.scores }) aipw.scores&lt;- unname(do.call(c, aipw.scores)) # Estimate average treatment effect conditional on group membership fmla &lt;- formula(paste0(&#39;aipw.scores ~ factor(&#39;, group, &#39;)&#39;)) ols &lt;- lm(fmla, data=transform(data, aipw.scores=aipw.scores)) ols.res &lt;- coeftest(ols, vcov = vcovHC(ols, &quot;HC2&quot;)) indices &lt;- which(names(coef(ols.res)) != &#39;(Intercept)&#39;) summary_rw_lm(ols, indices=indices) ## Estimate Std. Error Orig. p-value Adj. p-value ## factor(polviews)2 -0.02431188 0.03025159 4.216022e-01 0.4196 ## factor(polviews)3 -0.06078026 0.03005945 4.318542e-02 0.0716 ## factor(polviews)4 -0.13363032 0.02815576 2.083662e-06 0.0000 ## factor(polviews)5 -0.16498404 0.02949527 2.244685e-08 0.0000 ## factor(polviews)6 -0.17926620 0.02958012 1.375097e-09 0.0000 ## factor(polviews)7 -0.18695392 0.03776909 7.466598e-07 0.0000 6.2 Data-driven hypotheses データを見る前にあらかじめ検証する仮説を決めておくことはp-cackingを避ける意味でも良いプラクティスである。ただし、有効な検定はsample splittingを行うことでもできる。sample splitting とは、よさそうなサブグループを見つけるためにデータの一部を用い、そのあと残りのサンプルを使ってこれらのサブグループに関する仮説検定を行う。このような仮説検定のためのサンプル分割はhonestyと呼ばれる。 Pre-specifying hypotheses prior to looking at the data is in general good practice to avoid “p-hacking” (e.g., slicing the data into different subgroups until a significant result is found). However, valid tests can also be attained if by sample splitting: we can use a subset of the sample to find promising subgroups, then test hypotheses about these subgroups in the remaining sample. This kind of sample splitting for hypothesis testing is called honesty. 6.2.1 Via causal trees Causal treeはランダム化を前提として処置効果が異なるサブグループを見つけることができる直感的なアルゴリズムである。 考え方としては、サンプルをsplitting、estimation、testにの3つに分割する（必ずしも同じ数のサンプル出なくてよい）。splittingは、決定木をフィットさせるのに使い、葉ごとの処置効果の差が最大になるように推定される。estimationサンプルは、それぞれの葉の処置効果を推定するために使われる。testサンプルは、木の推定値のヴァリデーションに使われる。 Causal trees (Athey and Imbens)(PNAS, 2016) are an intuitive algorithm that is available in the randomized setting to discover subgroups with different treatment effects. At a high level, the idea is to divide the sample into three subsets (not necessarily of equal size). The splitting subset is used to fit a decision tree whose objective is modified to maximize heterogeneity in treatment effect estimates across leaves. The estimation subset is then used to produce a valid estimate of the treatment effect at each leaf of the fitted tree. Finally, a test subset can be used to validate the tree estimates. The next snippet uses honest.causalTree function from the causalTree package. For more details, see the causalTree documentation. # Only valid for randomized data! fmla &lt;- paste(outcome, &quot; ~&quot;, paste(covariates, collapse = &quot; + &quot;)) # Dividing data into three subsets indices &lt;- split(seq(nrow(data)), sort(seq(nrow(data)) %% 3)) names(indices) &lt;- c(&#39;split&#39;, &#39;est&#39;, &#39;test&#39;) # Fitting the forest ct.unpruned &lt;- honest.causalTree( formula=fmla, # Define the model data=data[indices$split,], treatment=data[indices$split, treatment], est_data=data[indices$est,], est_treatment=data[indices$est, treatment], minsize=1, # Min. number of treatment and control cases in each leaf HonestSampleSize=length(indices$est), # Num obs used in estimation after splitting # We recommend not changing the parameters below split.Rule=&quot;CT&quot;, # Define the splitting option cv.option=&quot;TOT&quot;, # Cross validation options cp=0, # Complexity parameter split.Honest=TRUE, # Use honesty when splitting cv.Honest=TRUE # Use honesty when performing cross-validation ) # Table of cross-validated values by tuning parameter. ct.cptable &lt;- as.data.frame(ct.unpruned$cptable) # Obtain optimal complexity parameter to prune tree. cp.selected &lt;- which.min(ct.cptable$xerror) cp.optimal &lt;- ct.cptable[cp.selected, &quot;CP&quot;] # Prune the tree at optimal complexity parameter. ct.pruned &lt;- prune(tree=ct.unpruned, cp=cp.optimal) # Predict point estimates (on estimation sample) tau.hat.est &lt;- predict(ct.pruned, newdata=data[indices$est,]) # Create a factor column &#39;leaf&#39; indicating leaf assignment in the estimation set num.leaves &lt;- length(unique(tau.hat.est)) leaf &lt;- factor(tau.hat.est, levels=sort(unique(tau.hat.est)), labels = seq(num.leaves)) 注：まったく木が分割しない場合には、各葉の最小サンプル数を調整するパラメータであるminsizeを減らすと良い。以下のコードではTreeを描画する。セルの中の値は処置効果の推定値と、各葉に落ちるサンプルの割合の推定値をあらわしている。これらはestimationサンプルを使って推定されている。 Note: if your tree is not splitting at all, try decreasing the parameter minsize that controls the minimum size of each leaf. The next snippet plots the learned tree. The values in the cell are the estimated treatment effect and an estimate of the fraction of the population that falls within each leaf. Both are estimated using the estimation sample. rpart.plot( x=ct.pruned, # Pruned tree type=3, # Draw separate split labels for the left and right directions fallen=TRUE, # Position the leaf nodes at the bottom of the graph leaf.round=1, # Rounding of the corners of the leaf node boxes extra=100, # Display the percentage of observations in the node branch=.1, # Shape of the branch lines box.palette=&quot;RdBu&quot;) # Palette for coloring the node The next snippet tests if the treatment effect in leaves \\(\\geq 2\\) is larger than the treatment effect in the first leaf. The code follows closely what we saw in the previous subsection. # This is only valid in randomized datasets. fmla &lt;- paste0(outcome, &#39; ~ &#39;, paste0(treatment, &#39;* leaf&#39;)) if (num.leaves == 1) { print(&quot;Skipping since there&#39;s a single leaf.&quot;) } else if (num.leaves == 2) { # if there are only two leaves, no need to correct for multiple hypotheses ols &lt;- lm(fmla, data=transform(data[indices$est,], leaf=leaf)) coeftest(ols, vcov=vcovHC(ols, &#39;HC2&#39;))[4,,drop=F] } else { # if there are three or more leaves, use Romano-Wolf test correction ols &lt;- lm(fmla, data=transform(data[indices$est,], leaf=leaf)) interact &lt;- which(sapply(names(coef(ols)), function(x) grepl(paste0(treatment, &quot;:&quot;), x))) summary_rw_lm(ols, indices=interact, cov.type = &#39;HC2&#39;) } ## Estimate Std. Error Orig. p-value Adj. p-value ## w:leaf2 0.04261544 0.02675955 1.112984e-01 0.1137 ## w:leaf3 0.08304080 0.03903846 3.343291e-02 0.0629 ## w:leaf4 0.08649780 0.02999722 3.941285e-03 0.0113 ## w:leaf5 0.10688672 0.03346314 1.406931e-03 0.0047 ## w:leaf6 0.14399896 0.03708540 1.039142e-04 0.0005 ## w:leaf7 0.17514244 0.03797784 4.045881e-06 0.0000 ## w:leaf8 0.21914803 0.04269808 2.915505e-07 0.0000 ## w:leaf9 0.23088896 0.06627687 4.967474e-04 0.0024 In the chapter Introduction to Machine Learning, we cautioned against interpreting the decision tree splits, and the same is true for causal tree splits. That a tree splits on a particular variable does not mean that this variable is relevant in the underlying data-generating process – it could simply be correlated with some other variable that is. For the same reason, we should not try to interpret partial effects from tree output. However, similar to what we have done in previous chapters, we can try to understand how the joint distribution of covariates varies for subgroups with different estimated treatment effects. The annotated heatmap below shows the average value of each covariate within each leaf. Leaves are ordered from lowest to highest treatment effect estimate. The color is a normalized distance of each leaf-specific covariate mean from the overall covariate mean, i.e.., \\(\\smash{\\Phi^{-1}\\left((\\widehat{\\text{E}}[X_i|L_i] - \\widehat{\\text{E}}[X_i])/\\widehat{\\text{Var}}(\\widehat{\\text{E}}[X_i|L_i])\\right)}\\). The rows are in descending order of variation, measured by \\(\\widehat{\\text{Var}}(\\widehat{\\text{E}}[X_i|L_i])/\\widehat{\\text{Var}}(X_i)\\). df &lt;- mapply(function(covariate) { # Looping over covariate names # Compute average covariate value per leaf (with correct standard errors) fmla &lt;- formula(paste0(covariate, &quot;~ 0 + leaf&quot;)) ols &lt;- lm(fmla, data=transform(data[indices$est,], leaf=leaf)) ols.res &lt;- coeftest(ols, vcov=vcovHC(ols, &quot;HC2&quot;)) # Retrieve results avg &lt;- ols.res[,1] stderr &lt;- ols.res[,2] # Tally up results data.frame(covariate, avg, stderr, leaf=paste0(&quot;Leaf&quot;, seq(num.leaves)), # Used for coloring scaling=pnorm((avg - mean(avg))/sd(avg)), # We will order based on how much variation is &#39;explain&#39; by the averages # relative to the total variation of the covariate in the data variation=sd(avg) / sd(data[,covariate]), # String to print in each cell in heatmap below labels=paste0(signif(avg, 3), &quot;\\n&quot;, &quot;(&quot;, signif(stderr, 3), &quot;)&quot;)) }, covariates, SIMPLIFY = FALSE) df &lt;- do.call(rbind, df) # a small optional trick to ensure heatmap will be in decreasing order of &#39;variation&#39; df$covariate &lt;- reorder(df$covariate, order(df$variation)) # plot heatmap ggplot(df) + aes(leaf, covariate) + geom_tile(aes(fill = scaling)) + geom_text(aes(label = labels)) + scale_fill_gradient(low = &quot;#E1BE6A&quot;, high = &quot;#40B0A6&quot;) + ggtitle(paste0(&quot;Average covariate values within each leaf&quot;)) + theme_minimal() + ylab(&quot;&quot;) + xlab(&quot;&quot;) + theme(plot.title = element_text(size = 12, face = &quot;bold&quot;), axis.text=element_text(size=11)) Interpret the heatmap above. What describes the subgroups with strongest and weakest estimated treatment effect? 6.2.2 Via grf The function causal_forest from the package grf allows us to get estimates of the CATE (6.1). # Get predictions from forest fitted above. tau.hat &lt;- predict(forest.tau)$predictions # tau(X) estimates CFなどのノンパラ手法を使ったとき、その処置効果の予測値の分布を見たくなるかもしれない。もしヒストグラムが一点に集中していたら異質性がなさそうで、ヒストグラムが広がっていたら異質性がありそうだと考えるかもしれない。しかし、その考え方は間違っている。 Having fit a non-parametric method such as a causal forest, a researcher may (incorrectly) start by looking at the distribution of its predictions of the treatment effect. One might be tempted to think: “if the histogram is concentrated at a point, then there is no heterogeneity; if the histogram is spread out, then our estimator has found interesting heterogeneity.” However, this may be false. # Do not use this for assessing heterogeneity. See text above. hist(tau.hat, main=&quot;CATE estimates&quot;, freq=F) もしヒストグラムが一点に集中していれば、単純に検出力不足かもしれない。すなわち異質性を検出できなかったが、もっとデータが多ければ検出できるかもしれない。ヒストグラムが広がっているのは、オーバーフィットしている可能性がある。ノイズを含んで条件付き処置効果を推定してしまっているかもしれず、実際には条件付き処置効果はもっとxに対してなめらかな形かもしれない。 If the histogram is concentrated at a point, we may simply be underpowered: our method was not able to detect any heterogeneity, but maybe it would detect it if we had more data. If the histogram is spread out, we may be overfitting: our model is producing very noisy estimates \\(\\widehat{\\tau}(x)\\), but in fact the true \\(\\tau(x)\\) can be much smoother as a function of \\(x\\). grfパッケージは変数重要度を出力することができる。変数重要度とは、その変数がどれくらい多く木の分割基準として使われたかを表す。ヒストグラムの例と同様に、これも荒い診断にはなるが、重要度が低い変数は異質性をもたらしていないといった簡単に結論付けをすることはできない。これには、causal treeの節で見てきたことと同様の説明が可能である。もし2つの変数が高い相関を持っていれば、例え2変数ともDGP的には意味を持っていたとしても（もしくは2変数とも関係なかったとしても）片方の変数だけを用いて木の分割は行われてもおかしくない。 The grf package also produces a measure of variable importance that indicates how often a variable was used in a tree split. Again, much like the histogram above, this can be a rough diagnostic, but it should not be interpreted as indicating that, for example, variable with low importance is not related to heterogeneity. The reasoning is the same as the one presented in the causal trees section: if two covariates are highly correlated, the trees might split on one covariate but not the other, even though both (or maybe neither) are relevant in the true data-generating process. var_imp &lt;- c(variable_importance(forest.tau)) names(var_imp) &lt;- covariates sorted_var_imp &lt;- sort(var_imp, decreasing = TRUE) sorted_var_imp[1:5] # showing only first few ## polviews income age educ marital ## 0.42566545 0.35099325 0.09706847 0.07540505 0.04353924 6.2.2.1 Data-driven subgroups Causal treeと同様に、Causal forestを使ってサブグループにサンプルを分けることができる。葉の代わりに、推定されたCATEをもとに、サンプルを順位付けをして、例えば５分割にすることができる。 （メモ：CATE自体は、すべてのサンプルに計算されるため、それをランク付けすることはできる。ただし、それだとあるobsをCATEのモデル推定と、CATEの推定の両方に使ってしまうこととなり良くない。なので、fold1~4でモデル推定、fold5で推定。 難しいが検討すべき重要な点がある。すでに述べたように、サンプルiに対してCATEを推定するときには、サンプルiを用いてフィットされたモデルを一般に使うべきではない。このようなサンプル分割（上でhonestyと呼んだもの）は、CATEをバイアスなく推定するための一つの材料となる。しかし、もし二つの観測iとjについて順位付けをしようと思うと、より強い仮定として、モデルはiもjも使わずに推定されている必要がある。 Just as with causal trees, we can use causal forests to divide our observations into subgroups. In place of leaves, we’ll rank observation into (say) quintiles according to their estimated CATE prediction; see, e.g., Chernozhukov, Demirer, Duflo, Fernández-Val (2020) for similar ideas. There’s a subtle but important point that needs to be addressed here. As we have mentioned before, when predicting the conditional average treatment effect \\(\\widehat{\\tau}(X_i)\\) for observation \\(i\\) we should in general avoid using a model that was fitted using observation \\(i\\). This sort of sample splitting (which we called honesty above) is one of the required ingredients to get unbiased estimates of the CATE using the methods described here. However, when ranking estimates of two observations \\(i\\) and \\(j\\), we need something a little stronger: we must ensure that the model was not fit using either \\(i\\) or \\(j\\)’s data. これを克服する方法は単純である。まずデータをK個のサンプル群に分ける。次に、群ごとに順番に、CATEモデルをK-1個の群にフィットさせる。その上で、残しておいた１つの群に対して、「別々に」まだ見ていないサンプルをQ個のグループに順位付けをする。（Q=5の場合、CATEに基づき1分位グループ、2分位グループなどと分ける）それらのランク付けを統合して、それぞれの観測値のCATEの違いを分析することができる。 このgistはこれをgrfで計算する。forestではなく他のノンパラメソッドに変えて同じことを行うのは難しくない。ただし、grfは特に、有効なランク付けを行うためのちょっとした仕掛けがある。それは、フォールドのインデックスのベクトルをcausal_forest関数のclustersオプションに渡すことができ、それｗぞれのfoldの中での観測値のランク漬けをできることである。それぞれのfoldの木々における推定値は、そのfold以外のサンプルを使って構築された木で推定されているため、うまくいく。 One way of overcoming this obstacle is simple. First, divide the data into \\(K\\) folds (subsets). Then, cycle through the folds, fitting a CATE model on \\(K-1\\) folds. Next, for each held-out fold, separately rank the unseen observations into \\(Q\\) groups based on their prediction (i.e., if \\(Q=5\\), then we rank observations by estimated CATE into “top quintile”, “second quintile”, and so on). After concatenating the independent rankings together, we can study the differences in observations in each rank-group. This gist computes the above for grf, and it should not be hard to modify it so as to replace forests by any other non-parametric method. However, for grf specifically, there’s a small trick that allows us to obtain a valid ranking: we can pass a vector of fold indices to the argument clusters and rank observations within each fold. This works because estimates for each fold (“cluster”) trees are computed using trees that were not fit using observations from that fold. Here’s how to do it. # Valid randomized data and observational data with unconfoundedness+overlap. # Note: read the comments below carefully. # In randomized settings, do not estimate forest.e and e.hat; use known assignment probs. # Prepare dataset fmla &lt;- formula(paste0(&quot;~ 0 + &quot;, paste0(covariates, collapse=&quot;+&quot;))) X &lt;- model.matrix(fmla, data) W &lt;- data[,treatment] Y &lt;- data[,outcome] # Number of rankings that the predictions will be ranking on # (e.g., 2 for above/below median estimated CATE, 5 for estimated CATE quintiles, etc.) num.rankings &lt;- 5 # Prepare for data.splitting # Assign a fold number to each observation. # The argument &#39;clusters&#39; in the next step will mimick K-fold cross-fitting. # clustersにグループのインデックスを渡すことで、K-fold cross-fittingをまねることができる。 # サンプルサイズ分のしーくんすを作って、それをfold数で割った余りを取ることで、グループ番号を振る。 # foldsは c(1,1,1,...2,2,2....,3,3,3,...,)というベクトルになっている。 num.folds &lt;- 10 folds &lt;- sort(seq(n) %% num.folds) + 1 # Comment or uncomment depending on your setting. # Observational setting with unconfoundedness+overlap (unknown assignment probs): # forest &lt;- causal_forest(X, Y, W, clusters = folds) # Randomized settings with fixed and known probabilities (here: 0.5). # 上で用意したfoldsをclustersに渡す。 forest &lt;- causal_forest(X, Y, W, W.hat=.5, clusters = folds) # Retrieve out-of-bag predictions. # Predictions for observation in fold k will be computed using # trees that were not trained using observations for that fold. tau.hat &lt;- predict(forest)$predictions # ランク付けをする。fold順に、当該foldにおけるtau.hatを持ってきて、quantile関数で順位付けする。 # tau.hat.quantilesは5分位の切れ目を出している。 # これを切れ目として、cut関数で切る # 1つ目のfoldは、このfoldで推定されたtau.hatを5分位で切る。この5分位点をもとに、このfoldについては順位付けをするということ。 # Rank observations *within each fold* into quintiles according to their CATE predictions. ranking &lt;- rep(NA, n) for (fold in seq(num.folds)) { tau.hat.quantiles &lt;- quantile(tau.hat[folds == fold], probs = seq(0, 1, by=1/num.rankings)) ranking[folds == fold] &lt;- cut(tau.hat[folds == fold], tau.hat.quantiles, include.lowest=TRUE, labels=seq(num.rankings)) } 以下はメモ。tau.hatが各ランキングでオーバーラップする。 tt&lt;-tibble(ranking,tau.hat) tt %&gt;% group_by(ranking) %&gt;% summarize(min(tau.hat),max(tau.hat)) ## # A tibble: 5 x 3 ## ranking `min(tau.hat)` `max(tau.hat)` ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 -0.629 -0.424 ## 2 2 -0.444 -0.372 ## 3 3 -0.392 -0.321 ## 4 4 -0.345 -0.251 ## 5 5 -0.278 0.00488 以下のコードは、上で定義されたグループごとのATEを計算する。これは2つの方法でできる。まず、単純にそれぞれのグループにおけるATEの差をみる方法である。これはランダム化されている場合のみ有効な方法である。 The next snippet computes the average treatment effect within each group defined above, i.e., \\(\\mathop{\\mathrm{E}}[Y_i(1) - Y_i(0)|G_i = g]\\). This can done in two ways. First, by computing a simple difference-in-means estimate of the ATE based on observations within each group. This is valid only in randomized settings. # Valid only in randomized settings. # Average difference-in-means within each ranking # グループダミーと処置とグループの交差項を入れてOLSするだけ # Formula y ~ 0 + ranking + ranking:w fmla &lt;- paste0(outcome, &quot; ~ 0 + ranking + ranking:&quot;, treatment) ols.ate &lt;- lm(fmla, data=transform(data, ranking=factor(ranking))) ols.ate &lt;- coeftest(ols.ate, vcov=vcovHC(ols.ate, type=&#39;HC2&#39;)) interact &lt;- which(grepl(&quot;:&quot;, rownames(ols.ate))) ols.ate &lt;- data.frame(&quot;ols&quot;, paste0(&quot;Q&quot;, seq(num.rankings)), ols.ate[interact, 1:2]) rownames(ols.ate) &lt;- NULL # just for display colnames(ols.ate) &lt;- c(&quot;method&quot;, &quot;ranking&quot;, &quot;estimate&quot;, &quot;std.err&quot;) ols.ate ## method ranking estimate std.err ## 1 ols Q1 -0.4426981 0.011318499 ## 2 ols Q2 -0.3913922 0.011220876 ## 3 ols Q3 -0.3615371 0.011012274 ## 4 ols Q4 -0.3280377 0.010481311 ## 5 ols Q5 -0.2145588 0.009766637 もう一つの方法としては、AIPWをそれぞれのグループで平均をとる方法である。この方法はランダム化されたサンプルでも、観察データでも（UnconfoundednessとOverlap条件が満たされていてれば）利用可能である。さらに、AIPWベースの推定は大サンプルにおいてより狭い信頼区間を構築することができる。 Another option is to average the AIPW scores within each group. This valid for both randomized settings and observational settings with unconfoundedness and overlap. Moreover, AIPW-based estimators should produce estimates with tighter confidence intervals in large samples. # Computing AIPW scores. tau.hat &lt;- predict(forest)$predictions e.hat &lt;- forest$W.hat # P[W=1|X] m.hat &lt;- forest$Y.hat # E[Y|X] # Estimating mu.hat(X, 1) and mu.hat(X, 0) for obs in held-out sample # Note: to understand this, read equations 6-8 in this vignette: # https://grf-labs.github.io/grf/articles/muhats.html mu.hat.0 &lt;- m.hat - e.hat * tau.hat # E[Y|X,W=0] = E[Y|X] - e(X)*tau(X) mu.hat.1 &lt;- m.hat + (1 - e.hat) * tau.hat # E[Y|X,W=1] = E[Y|X] + (1 - e(X))*tau(X) # AIPW scores aipw.scores &lt;- tau.hat + W / e.hat * (Y - mu.hat.1) - (1 - W) / (1 - e.hat) * (Y - mu.hat.0) ols &lt;- lm(aipw.scores ~ 0 + factor(ranking)) forest.ate &lt;- data.frame(&quot;aipw&quot;, paste0(&quot;Q&quot;, seq(num.rankings)), coeftest(ols, vcov=vcovHC(ols, &quot;HC2&quot;))[,1:2]) colnames(forest.ate) &lt;- c(&quot;method&quot;, &quot;ranking&quot;, &quot;estimate&quot;, &quot;std.err&quot;) rownames(forest.ate) &lt;- NULL # just for display forest.ate ## method ranking estimate std.err ## 1 aipw Q1 -0.4424803 0.011049087 ## 2 aipw Q2 -0.3929507 0.010791788 ## 3 aipw Q3 -0.3602181 0.010615964 ## 4 aipw Q4 -0.3297784 0.010208337 ## 5 aipw Q5 -0.2104361 0.009309925 The code below plots the estimates. # Concatenate the two results. res &lt;- rbind(forest.ate, ols.ate) # Plotting the point estimate of average treatment effect # and 95% confidence intervals around it. ggplot(res) + aes(x = ranking, y = estimate, group=method, color=method) + geom_point(position=position_dodge(0.2)) + geom_errorbar(aes(ymin=estimate-2*std.err, ymax=estimate+2*std.err), width=.2, position=position_dodge(0.2)) + ylab(&quot;&quot;) + xlab(&quot;&quot;) + ggtitle(&quot;Average CATE within each ranking (as defined by predicted CATE)&quot;) + theme_minimal() + theme(legend.position=&quot;bottom&quot;, legend.title = element_blank()) もし検出可能なだけの異質性がない場合には、上のプロットは、単調でなくなることもある。これはサンプル数が少なすぎて、処置効果の差が見られるようなサブグループを検出できなかったことを意味する。 演習として、上の2つのコードを少ないサンプル数で試してみよ（例えば最初の1000のサンプルのみを用いるなど）。おそらく非単調となるケースが確認できるだろう。 When there isn’t much detectable heterogeneity, the plot above can end up being non-monotonic. This can mean that the number of observations is too small for us to be able to detect subgroups with relevant differences in treatment effect. As an exercise, try running the previous two snippets on few data points (e.g., the first thousand observations only). You will likely see the “non-monotonicity” phenomenon just described. 次に、causal treeでやったように、グループ２やグループ３の推定値がグループ１に比べて大きいのかといった検定を行うことができる。平均値の差の推定値に基づく検定方法をいかに示す。Romano-Wolfの複数仮説検定の補正に注意せよ。 Next, as we did for leaves in a causal tree, we can test e.g., if the prediction for groups 2, 3, etc. are larger than the one in the first group. Here’s how to do it based on a difference-in-means estimator. Note the Romano-Wolf multiple-hypothesis testing correction. # Valid in randomized settings only. # y ~ ranking + w + ranking:w fmla &lt;- paste0(outcome, &quot;~ ranking + &quot;, treatment, &quot; + ranking:&quot;, treatment) ols &lt;- lm(fmla, data=transform(data, ranking=factor(ranking))) interact &lt;- which(sapply(names(coef(ols)), function(x) grepl(&quot;:&quot;, x))) res &lt;- summary_rw_lm(ols, indices=interact) rownames(res) &lt;- paste(&quot;Rank&quot;, 2:num.rankings, &quot;- Rank 1&quot;) # just for display res ## Estimate Std. Error Orig. p-value Adj. p-value ## Rank 2 - Rank 1 0.05130589 0.01475862 5.090710e-04 5e-04 ## Rank 3 - Rank 1 0.08116094 0.01474333 3.724843e-08 0e+00 ## Rank 4 - Rank 1 0.11466040 0.01473507 7.409688e-15 0e+00 ## Rank 5 - Rank 1 0.22813924 0.01474804 9.254246e-54 0e+00 # 分析手法の確認のために追加.以下と同じことをやっている。 data %&gt;% lm(y~w*factor(ranking),data=.) %&gt;% summary_rw_lm(indices=interact) ## Estimate Std. Error Orig. p-value Adj. p-value ## w:factor(ranking)2 0.05130589 0.01475862 5.090710e-04 6e-04 ## w:factor(ranking)3 0.08116094 0.01474333 3.724843e-08 0e+00 ## w:factor(ranking)4 0.11466040 0.01473507 7.409688e-15 0e+00 ## w:factor(ranking)5 0.22813924 0.01474804 9.254246e-54 0e+00 # rwはRomano Wolfの補正のp値を出すための関数 以下はAIPWベースの推定である。これもRomano Wolfの補正をしている。 Here’s how to do it for AIPW-based estimates, again with Romano-Wolf correction for multiple hypothesis testing. # Valid in randomized and observational settings with unconfoundedness+overlap. # Using AIPW scores computed above ols &lt;- lm(aipw.scores ~ 1 + factor(ranking)) res &lt;- summary_rw_lm(ols, indices=2:num.rankings) rownames(res) &lt;- paste(&quot;Rank&quot;, 2:num.rankings, &quot;- Rank 1&quot;) # just for display res ## Estimate Std. Error Orig. p-value Adj. p-value ## Rank 2 - Rank 1 0.04952957 0.01472507 7.702729e-04 4e-04 ## Rank 3 - Rank 1 0.08226219 0.01472378 2.330837e-08 0e+00 ## Rank 4 - Rank 1 0.11270184 0.01472442 2.008238e-14 0e+00 ## Rank 5 - Rank 1 0.23204415 0.01472507 1.030543e-55 0e+00 最後に、グループごとの共変量の平均値を比較することもできる。 Finally, we can also check if different groups have different average covariate levels across rankings. df &lt;- mapply(function(covariate) { # Looping over covariate names # Compute average covariate value per ranking (with correct standard errors) fmla &lt;- formula(paste0(covariate, &quot;~ 0 + ranking&quot;)) ols &lt;- lm(fmla, data=transform(data, ranking=factor(ranking))) ols.res &lt;- coeftest(ols, vcov=vcovHC(ols, &quot;HC2&quot;)) # Retrieve results avg &lt;- ols.res[,1] stderr &lt;- ols.res[,2] # Tally up results data.frame(covariate, avg, stderr, ranking=paste0(&quot;Q&quot;, seq(num.rankings)), # Used for coloring scaling=pnorm((avg - mean(avg))/sd(avg)), # We will order based on how much variation is &#39;explain&#39; by the averages # relative to the total variation of the covariate in the data variation=sd(avg) / sd(data[,covariate]), # String to print in each cell in heatmap below labels=paste0(signif(avg, 3), &quot;\\n&quot;, &quot;(&quot;, signif(stderr, 3), &quot;)&quot;)) }, covariates, SIMPLIFY = FALSE) df &lt;- do.call(rbind, df) # a small optional trick to ensure heatmap will be in decreasing order of &#39;variation&#39; df$covariate &lt;- reorder(df$covariate, order(df$variation)) # plot heatmap ggplot(df) + aes(ranking, covariate) + geom_tile(aes(fill = scaling)) + geom_text(aes(label = labels)) + scale_fill_gradient(low = &quot;#E1BE6A&quot;, high = &quot;#40B0A6&quot;) + ggtitle(paste0(&quot;Average covariate values within group (based on CATE estimate ranking)&quot;)) + theme_minimal() + ylab(&quot;&quot;) + xlab(&quot;CATE estimate ranking&quot;) + theme(plot.title = element_text(size = 11, face = &quot;bold&quot;), axis.text=element_text(size=11)) 上のヒートマップを解釈する。処置効果の推定値が大きいようなサブグループをあらわしているような共変量は何か。ランキングごとに単調に増加するような共変量はあるか？ Interpret the heatmap above. What describes the subgroups with strongest and weakest estimated treatment effect? Are there variables that seem to increase or decrease monotonically across rankings? 6.2.2.2 Best linear projection grf::best_linear_projectoin関数は、Doubly robustな処置効果の共変量への線形モデルでのフィットを行う。この回帰の係数は一般的なトレンドを示しているが、部分効果として解釈されるべきではない。処置効果と共変量の真の関係性が実際に線形であれば良いが、一般的にそれを仮定するべきではない。 This function provides a doubly robust fit to the linear model \\(\\widehat{\\tau}(X_i) = \\beta_0 + A_i&#39;\\beta_1\\), where \\(A_i\\) can be a subset of the covariate columns. The coefficients in this regression are suggestive of general trends, but they should not be interpret as partial effects – that would only be true if the true model were really linear in covariates, and that’s an assumption we shouldn’t be willing to make in general. # Best linear projection of the conditional average treatment effect on covariates best_linear_projection(forest.tau, X) ## ## Best linear projection of the conditional average treatment effect. ## Confidence intervals are cluster- and heteroskedasticity-robust (HC3): ## ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.17904089 0.04251023 -4.2117 2.542e-05 *** ## age 0.00147085 0.00031083 4.7321 2.233e-06 *** ## polviews -0.03546196 0.00356709 -9.9414 &lt; 2.2e-16 *** ## income -0.02105844 0.00201947 -10.4277 &lt; 2.2e-16 *** ## educ 0.00894557 0.00172605 5.1827 2.202e-07 *** ## marital 0.01047681 0.00331717 3.1584 0.001588 ** ## sex -0.00600787 0.01001081 -0.6001 0.548419 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 6.2.2.3 Assessing heterogeneity test_calibration関数は、Best linear predictorのCATEをout-of-bag推定による推定値を返す。これを実施すると以下の線形モデルのようになる。（メモ：m(X)がおそらく The function test_calibration computes an estimate of the best linear predictor of true CATE based on out-of-bag predictions \\(\\hat{\\tau}^{-i}(\\cdot)\\). The exact implementation seeks to fit the following linear model: \\[ \\begin{equation} Y_{i} - \\hat{m}^{-i}(X_{i}) = \\alpha\\bar{\\tau}\\left(W_{i} - \\hat{e}^{-i}(X_{i})\\right) + \\beta \\left(\\hat{\\tau}^{-i}(X_{i}) - \\bar{\\tau} \\right) \\left(W_{i} - \\hat{e}^{-i}(X_{i}) \\right) + \\epsilon, \\end{equation} \\] 係数αとベータは推定値の性能を評価することとなる。αが１であれば、平均的な予測は正しいこととなる。一方で、βが１となれば、Forestによる予測は実際の異質性をとらえていることとなる。 βはCATE予測が真のCATEに伴いどれだけ変わるかをあらわしている。したがって、p値は異質性があるかどうかのオムニバステストのようにもなる。この推定値が0より優位に大きければ、異質性がないという帰無仮説を棄却することができる。しかし、推定値がゼロより小さいことはあまり意味がなく、解釈できない。 where \\(\\bar{\\tau} := n^{-1}\\sum_{i=1}^{n} \\hat{\\tau}^{-i}(X_{i})\\). The coefficients \\(\\alpha\\) and \\(\\beta\\) allow us to evaluate the performance of our estimates. If \\(\\alpha = 1\\), then the average prediction produced by the forest is correct. Meanwhile, if \\(\\beta = 1\\), then the forest predictions adequately capture the underlying heterogeneity. The slope \\(\\beta\\) is a measure of how the CATE predictions covary with true CATE. Therefore, the p-value on the estimate of coefficient also acts as an omnibus test for the presence of heterogeneity. If the coefficient is significantly greater than zero, then we can reject the null of no heterogeneity. However, coefficients smaller than 0 are not meaningful and show not be interpreted. test_calibration(forest.tau) ## ## Best linear fit using forest predictions (on held-out data) ## as well as the mean forest prediction as regressors, along ## with one-sided heteroskedasticity-robust (HC3) SEs: ## ## Estimate Std. Error t value Pr(&gt;t) ## mean.forest.prediction 1.001339 0.013712 73.029 &lt; 2.2e-16 *** ## differential.forest.prediction 0.908107 0.048056 18.897 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Interpret the test above. Is the forest producing correct estimate of the average treatment effect? Is it capturing the underlying heterogeneity? 6.2.2.4 Partial dependence 他の変数はすべて固定したうえで、一つの変数のみを変えた場合に、CATEの推定値がどのようになるか、という点も興味深いだろう。以下のプロットでは、他の変数をすべてメディアんに固定した上で、関心のある変数を分位点にわたって評価する。 重要なのは、メディアんに固定することで、データポイントが少ないもしくは全く存在しないような領域でCATEを評価してしまうかもしれない。また、一部の変数を固定した上でその他の変数を動かすのはあまり面白くないかもしれにあ。 以下では、causal_forest予測を再び行い、今度は分散の推定も行う。estimate.variances=TRUEとすることで、漸近分散を得ることができる。grfは漸近正規性を持つため、信頼区間も構築することができる。（メモ：他のXは固定した上で、ある関心のあるXに対するτの信頼区間ということか。） It may also be interesting to examine how our CATE estimates behave when we change a single covariate, while keeping all the other covariates at a some fixed value. In the plot below we evaluate a variable of interest across quantiles, while keeping all other covariates at their median. It is important to recognize that by keeping some variables at their median we may be evaluating the CATE at \\(x\\) values in regions where there are few or no data points. Also, it may be the case that varying some particular variable while keeping others fixed may just not be very interesting. In what follows we’ll again use causal_forest predictions, along with their variance estimates (set estimate.variances=TRUE when predicting to we get estimates of the asymptotic variance of the prediction for each point). Since grf predictions are asymptotically normal, we can construct 95% confidence intervals in the usual manner (i.e., \\(\\hat{\\tau}(x) \\pm 1.96\\sqrt{\\widehat{\\text{Var}}(\\hat{\\tau}(x))}\\)). selected.covariate &lt;- &quot;polviews&quot; other.covariates &lt;- covariates[which(covariates != selected.covariate)] # Fitting a forest # (commented for convenience; no need re-fit if already fitted above) fmla &lt;- formula(paste0(&quot;~ 0 + &quot;, paste0(covariates, collapse=&quot;+&quot;))) # Note: For smaller confidence intervals, set num.trees ~ sample size # X &lt;- model.matrix(fmla, data) # W &lt;- data[,treatment] # Y &lt;- data[,outcome] # forest.tau &lt;- causal_forest(X, Y, W, W.hat=.5) # few trees for speed here # Compute a grid of values appropriate for the selected covariate grid.size &lt;- 7 covariate.grid &lt;- seq(min(data[,selected.covariate]), max(data[,selected.covariate]), length.out=grid.size) # Other options for constructing a grid: # For a binary variable, simply use 0 and 1 # grid.size &lt;- 2 # covariate.grid &lt;- c(0, 1) # For a continuous variable, select appropriate percentiles # percentiles &lt;- c(.1, .25, .5, .75, .9) # grid.size &lt;- length(percentiles) # covariate.grid &lt;- quantile(data[,selected.covariate], probs=percentiles) # Take median of other covariates medians &lt;- apply(data[, other.covariates, F], 2, median) # Construct a dataset data.grid &lt;- data.frame(sapply(medians, function(x) rep(x, grid.size)), covariate.grid) colnames(data.grid) &lt;- c(other.covariates, selected.covariate) # Expand the data X.grid &lt;- model.matrix(fmla, data.grid) # Point predictions of the CATE and standard errors forest.pred &lt;- predict(forest.tau, newdata = X.grid, estimate.variance=TRUE) tau.hat &lt;- forest.pred$predictions tau.hat.se &lt;- sqrt(forest.pred$variance.estimates) # Plot predictions for each group and 95% confidence intervals around them. data.pred &lt;- transform(data.grid, tau.hat=tau.hat, ci.low = tau.hat - 2*tau.hat.se, ci.high = tau.hat + 2*tau.hat.se) ggplot(data.pred) + geom_line(aes_string(x=selected.covariate, y=&quot;tau.hat&quot;, group = 1), color=&quot;black&quot;) + geom_errorbar(aes_string(x=selected.covariate, ymin=&quot;ci.low&quot;, ymax=&quot;ci.high&quot;, width=.2), color=&quot;blue&quot;) + ylab(&quot;&quot;) + ggtitle(paste0(&quot;Predicted treatment effect varying &#39;&quot;, selected.covariate, &quot;&#39; (other variables fixed at median)&quot;)) + scale_x_continuous(&quot;polviews&quot;, breaks=covariate.grid, labels=signif(covariate.grid, 2)) + theme_minimal() + theme(plot.title = element_text(size = 11, face = &quot;bold&quot;)) この例では、かなり大きな信頼区間となっている点に注意せよ。これは2つの観点から説明できる。まず、上で言及したように、データが少ない問題がある。例えば、polviewsが６であるようなデータ自体は少なくないにもかかわらず（以下のコードを走らせると全サンプルの15%は６である。）、 Note that, in this example, we got fairly large confidence intervals. This can be explained in two ways. First, as we mentioned above, there’s a data scarcity problem. For example, even though the number of observations with polviews equal to 6 is not small, with(data, mean(polviews == 6)) ## [1] 0.1545388 polviewが６であり、かつ、例えば年齢がメディアンに近いような人の数は遥かに少なくなってしまうし、 there’s a much smaller fraction of individuals with polviews equal to 6 and (say) age close to the median age, mean(with(data, (polviews == 6) &amp; (abs(age - median(age)) &lt;= 3))) # at most 3 yrs away ## [1] 0.02247583 さらに他の変数までメディアンに近いような人はさらに少なくなってしまう。２つ目の理由は、統計的な問題である。grfはノンパラモデルのため、比較的大きな信頼区間が構築される。特に高次元の問題の場合には顕著である。モデリングの仮定を避けたために生じる問題であり（パラメトリックな仮定をおかなかったから）、これは避けられない結果である。 and an even smaller fraction of observations with polviews equal to 6 and every other variable close to the median. The second cause of wide confidence intervals is statistical. Since grf is a non-parametric model, we should expect fairly wide confidence intervals, especially in high-dimensional problems – that is an unavoidable consequence of avoiding modeling assumptions. GRFの元論文でも指摘されているように、grfの信頼区間のカバレッジ範囲は、サンプル数に比較してシグナルが強すぎるか複雑すぎる場合において低下する。また、木の数を増やすことによってより狭い信頼区間を構築することが可能である。詳細はshort vignetteを参照せよ。 As documented in the original paper on generalized random forests (Athey, Tibshirani and Wager, 2019), the coverage of grf confidence intervals can drop if the signal is too dense or too complex relative to the number of observations. Also, to a point, it’s possible to get tighter confidence intervals by increasing the number of trees; see this short vignette for more information. 2つ以上の変数を同時に動かすことも可能である。以下のコードは、2つの変数を動かして得られた推定値と標準誤差である。 We can vary more than one variable at a time. The next snippet shows predictions and standard errors varying two variables. x1 &lt;- &#39;polviews&#39; x2 &lt;- &#39;age&#39; selected.covariates &lt;- c(x1, x2) other.covariates &lt;- covariates[-which(covariates %in% selected.covariates)] # Compute a grid of values appropriate for the selected covariate # See other options for constructing grids in the snippet above. x1.grid.size &lt;- 7 x2.grid.size &lt;- 5 x1.grid &lt;- seq(min(data[,x1]), max(data[,x1]), length.out=x1.grid.size) x2.grid &lt;- seq(min(data[,x2]), max(data[,x2]), length.out=x2.grid.size) # Take median of other covariates medians &lt;- apply(data[, other.covariates, F], 2, median) # Construct dataset data.grid &lt;- data.frame( sapply(medians, function(x) rep(x, grid.size)), expand.grid(x1.grid, x2.grid)) colnames(data.grid) &lt;- c(other.covariates, selected.covariates) # Expand the data according to formula used to fit forest X.grid &lt;- model.matrix(fmla, data.grid) # Forest-based point estimates of CATE and standard errors around them forest.pred &lt;- predict(forest.tau, newdata = X.grid, estimate.variance=TRUE) tau.hat &lt;- forest.pred$predictions tau.hat.se &lt;- sqrt(forest.pred$variance.estimates) # A vector of labels for plotting below labels &lt;- mapply(function(est, se) paste0(signif(est, 3), &quot;\\n&quot;, &quot;(&quot;, signif(se, 3), &quot;)&quot;), tau.hat, tau.hat.se) df &lt;- data.frame(X.grid, tau.hat, labels) # Plotting ggplot(df) + aes(age, polviews) + geom_tile(aes(fill = tau.hat)) + geom_text(aes(label = labels)) + scale_fill_gradient(low = &quot;blue&quot;, high = &quot;orange&quot;) + scale_y_continuous(&quot;polviews&quot;, breaks=x1.grid, labels=signif(x1.grid, 2)) + scale_x_continuous(&quot;age&quot;, breaks=x2.grid, labels=signif(x2.grid, 2)) + ggtitle(paste0(&quot;Predicted treatment effect varying &#39;&quot;, x1, &quot;&#39; and &#39;&quot;, x2, &quot;&#39; (other variables fixed at median)&quot;)) + theme_minimal() + theme(plot.title = element_text(size = 10, face = &quot;bold&quot;)) 6.2.3 実際の活用におけるプロセス ＧＲＦの活用に際して、ここではPre-specified hypothesisではなく、あくまでPostでの検討を考える。 まずはすべての変数（共変量）を使ってGRFにフィットさせる。 変数重要度を見ること。また、処置効果別の5分位点で比較してみること。、分位別の共変量の違いを観察することを行うべきである。 6.3 Further reading A readable summary of different method for hypothesis testing correction is laid out in the introduction to Clarke, Romano and Wolf (2009). Athey and Wager (2019) shows an application of causal forests to heterogeity analysis in a setting with clustering. "],["IPW.html", "chapter: 7 IPWや操作変数について 7.1 IPW 7.2 操作変数的な変数を調整したときに起こるZバイアス 7.3 直接効果と関節効果がある場合 7.4 処置の結果変数は操作変数になりうるか？", " chapter: 7 IPWや操作変数について 7.1 IPW 突然だがIPW推定量をここで見てみよう） 傾向スコアが高い人たちは処置を受けやすいと同時に、アウトカムも高くなりやすい。 だからInverse probabilityでウェイティングしようというアイデア。 Y1として、処置群におけるYの数を、増やすイメージ。例えば傾向スコアが0.3であればYが3倍に増える。（疑問：それでサンプル数と同じだけの人数になるのか？ すなわち、WY/eの期待値がY（W＝１）の期待値と一致するのか）処置軍において傾向スコアの逆数の和をとると、サンプルサイズになるというのは感覚的にわかる。傾向スコアが0.5なのであれば、実際にはその人数は倍ということなので。 (1/e)の処置群での和はサンプルサイズに等しくなる。 処置群において、処置群の人たちをバランスさせた上で、その人Nで割るのは、Horvitz-Thompson estimatorというらしい。 Hajek estimator IPWの本質は Data augmentation だと思っているのですが、「観測データの個数 nではなく、実際にどのくらい augmentation したのかに相当する項で割った方がよさそう」という気持ちを感じます。 https://fullflu.hatenablog.com/entry/2020/05/01/ipw#Horvitz-Thompson-estimator-%E3%81%A8%E3%81%AF \\[ Y=aX+bW+\\epsilon\\\\ p(W=1)=Normal(a+bX,\\epsilon)\\\\ ATE=\\frac{1}{N}\\sum_{W_i=1}\\frac{Y_i}{e(X_i)}-\\frac{1}{N}\\sum_{W_i=0}\\frac{Y_i}{1-e(X_i)}\\\\ ATE=\\frac{1}{\\sum \\frac{W_i}{e(X_i)}}\\sum\\frac{W_iY_i}{e(X_i)}- \\frac{1}{\\sum \\frac{1-W_i}{1-e(X_i)}}\\sum\\frac{(1-W_i)Y_i}{1-e(X_i)} \\] xx&lt;-rnorm(10000) p&lt;-pnorm(0.2+xx) w&lt;-rbinom(10000,1,p) yy&lt;-1+0.5*xx+0.8*w+rnorm(10000) dd&lt;-tibble(xx,p,w,yy) model&lt;-glm(w~xx,data=dd,family = binomial(&quot;logit&quot;)) dd&lt;-dd %&gt;% mutate(e=model$fitted.values) lm(yy~xx+w,data=dd) %&gt;% summary() ## ## Call: ## lm(formula = yy ~ xx + w, data = dd) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.6044 -0.6749 0.0043 0.6858 3.5826 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.02754 0.01653 62.17 &lt;2e-16 *** ## xx 0.50214 0.01197 41.96 &lt;2e-16 *** ## w 0.73940 0.02398 30.83 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9979 on 9997 degrees of freedom ## Multiple R-squared: 0.3711, Adjusted R-squared: 0.371 ## F-statistic: 2949 on 2 and 9997 DF, p-value: &lt; 2.2e-16 lm(yy~e+w,data=dd) %&gt;% summary() ## ## Call: ## lm(formula = yy ~ e + w, data = dd) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.6826 -0.6829 0.0072 0.6841 3.6734 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.06993 0.02219 3.152 0.00162 ** ## e 1.73951 0.04332 40.153 &lt; 2e-16 *** ## w 0.74303 0.02437 30.496 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.004 on 9997 degrees of freedom ## Multiple R-squared: 0.363, Adjusted R-squared: 0.3629 ## F-statistic: 2849 on 2 and 9997 DF, p-value: &lt; 2.2e-16 dd %&gt;% mutate(temp=w*yy/e-(1-w)*yy/(1-e)) %&gt;% summarize(mean(temp)) ## # A tibble: 1 x 1 ## `mean(temp)` ## &lt;dbl&gt; ## 1 0.741 dd %&gt;% mutate(temp=w*yy/e) %&gt;% summarize(mean(temp)) ## # A tibble: 1 x 1 ## `mean(temp)` ## &lt;dbl&gt; ## 1 1.75 dd %&gt;% mutate(temp=(1-w)*yy/(1-e)) %&gt;% summarize(mean(temp)) ## # A tibble: 1 x 1 ## `mean(temp)` ## &lt;dbl&gt; ## 1 1.01 dd %&gt;% filter(w==0) %&gt;% mutate(temp=yy/(1-e)) %&gt;% summarize(mean(temp)) ## # A tibble: 1 x 1 ## `mean(temp)` ## &lt;dbl&gt; ## 1 2.26 # 以下が1万にならないから、以下で割る必要がある。 dd %&gt;% mutate(temp=w/e) %&gt;% summarize(sum(temp)) ## # A tibble: 1 x 1 ## `sum(temp)` ## &lt;dbl&gt; ## 1 9843. dd %&gt;% mutate(temp=(1-w)/(1-e)) %&gt;% summarize(sum(temp)) ## # A tibble: 1 x 1 ## `sum(temp)` ## &lt;dbl&gt; ## 1 9896. 7.2 操作変数的な変数を調整したときに起こるZバイアス ああ #install.packages(&quot;ggdag&quot;) library(ggdag) library(tidyverse) tidy_dag_2 &lt;- ggdag::dagify( Y ~ D + U, D ~ Z + U, exposure = &quot;D&quot;, # 処置変数（暴露 [exposure]） を指定 outcome = &quot;Y&quot; , # 結果変数を指定 latent = &quot;U&quot;, # 未観測（潜在[latent]）変数を指定 coords = list(x = c(Z = 0, D = 1, Y = 3, U = 2), y = c(Z = 0, D = 0, Y = 0, U = 1)) ) %&gt;% ggdag::tidy_dagitty() ggdag::ggdag(tidy_dag_2) + theme_dag() DGPは以下とする。 u&lt;-rnorm(1000) z&lt;-rnorm(1000) d&lt;-1+2*z+3*u+rnorm(1000) y&lt;-0.5*d+0.8*u+rnorm(1000) dt&lt;-tibble(u,z,d,y) lm(y~d,data=dt) %&gt;%summary ## ## Call: ## lm(formula = y ~ d, data = dt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.6210 -0.7475 -0.0264 0.7844 3.4969 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.200215 0.035869 -5.582 3.07e-08 *** ## d 0.669071 0.008948 74.770 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.089 on 998 degrees of freedom ## Multiple R-squared: 0.8485, Adjusted R-squared: 0.8484 ## F-statistic: 5591 on 1 and 998 DF, p-value: &lt; 2.2e-16 lm(y~d+z,data=dt) %&gt;%summary ## ## Call: ## lm(formula = y ~ d + z, data = dt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.5702 -0.7499 -0.0203 0.8076 2.9451 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.25192 0.03420 -7.367 3.66e-13 *** ## d 0.72688 0.00994 73.125 &lt; 2e-16 *** ## z -0.42353 0.03835 -11.045 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.028 on 997 degrees of freedom ## Multiple R-squared: 0.865, Adjusted R-squared: 0.8648 ## F-statistic: 3195 on 2 and 997 DF, p-value: &lt; 2.2e-16 #install.packages(&quot;estimatr&quot;) library(estimatr) iv_robust(y ~ d | z, data = dt, se_type = &quot;classical&quot;) %&gt;%summary ## ## Call: ## iv_robust(formula = y ~ d | z, data = dt, se_type = &quot;classical&quot;) ## ## Standard error type: classical ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF ## (Intercept) -0.03114 0.04461 -0.6982 4.852e-01 -0.1187 0.05639 998 ## d 0.51835 0.01926 26.9132 2.162e-120 0.4806 0.55615 998 ## ## Multiple R-squared: 0.8055 , Adjusted R-squared: 0.8053 ## F-statistic: 724.3 on 1 and 998 DF, p-value: &lt; 2.2e-16 # ZXZY (z%*%y)/(z%*%d) ## [,1] ## [1,] 0.5178849 7.3 直接効果と関節効果がある場合 tidy_dag_2 &lt;- ggdag::dagify( Y ~ D + A + U, A ~ D + B, D ~ U, exposure = &quot;D&quot;, # 処置変数（暴露 [exposure]） を指定 outcome = &quot;Y&quot; , # 結果変数を指定 coords = list(x = c(B = 0, A = 2, Y = 3, D = 1, U=2), y = c(B = 1, A = 1, Y = 0.5, D = 0.5,U=0)) ) %&gt;% ggdag::tidy_dagitty() ggdag::ggdag(tidy_dag_2) + theme_dag() u&lt;-rnorm(1000) b&lt;-rnorm(1000) d&lt;-1+3*u+rnorm(1000) a&lt;-2+2*d+0.5*b+rnorm(1000) y&lt;-0.5*d+a+0.8*u+rnorm(1000) dt&lt;-tibble(u,d,y,a,b) lm(y~d+u,data=dt) %&gt;%summary #正しい総合効果は2.5 ## ## Call: ## lm(formula = y ~ d + u, data = dt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.6576 -1.0581 -0.0450 0.9733 4.3614 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.04545 0.06703 30.516 &lt; 2e-16 *** ## d 2.44245 0.04730 51.634 &lt; 2e-16 *** ## u 0.99958 0.15017 6.656 4.63e-11 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.509 on 997 degrees of freedom ## Multiple R-squared: 0.9712, Adjusted R-squared: 0.9712 ## F-statistic: 1.682e+04 on 2 and 997 DF, p-value: &lt; 2.2e-16 lm(y~d+a+u,data=dt) %&gt;%summary #正しい直接効果は0.5 ## ## Call: ## lm(formula = y ~ d + a + u, data = dt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.9130 -0.6525 -0.0081 0.6862 3.2309 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.003435 0.070924 0.048 0.961 ## d 0.445604 0.062701 7.107 2.26e-12 *** ## a 1.009484 0.027580 36.602 &lt; 2e-16 *** ## u 0.895338 0.098152 9.122 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9859 on 996 degrees of freedom ## Multiple R-squared: 0.9877, Adjusted R-squared: 0.9877 ## F-statistic: 2.671e+04 on 3 and 996 DF, p-value: &lt; 2.2e-16 lm(y~d+a,data=dt) %&gt;%summary ## ## Call: ## lm(formula = y ~ d + a, data = dt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.1291 -0.6385 -0.0021 0.7201 3.2600 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.27832 0.06642 -4.19 3.04e-05 *** ## d 0.69850 0.05851 11.94 &lt; 2e-16 *** ## a 1.01678 0.02868 35.45 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.026 on 997 degrees of freedom ## Multiple R-squared: 0.9867, Adjusted R-squared: 0.9867 ## F-statistic: 3.697e+04 on 2 and 997 DF, p-value: &lt; 2.2e-16 #install.packages(&quot;estimatr&quot;) library(estimatr) iv_robust(y ~ d+a | a+b, data = dt, se_type = &quot;classical&quot;) %&gt;%summary ## ## Call: ## iv_robust(formula = y ~ d + a | a + b, data = dt, se_type = &quot;classical&quot;) ## ## Standard error type: classical ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF ## (Intercept) -0.01584 0.12474 -0.127 8.990e-01 -0.2606 0.229 997 ## d 0.97995 0.12729 7.698 3.311e-14 0.7302 1.230 997 ## a 0.88091 0.06166 14.287 2.883e-42 0.7599 1.002 997 ## ## Multiple R-squared: 0.9864 , Adjusted R-squared: 0.9864 ## F-statistic: 3.61e+04 on 2 and 997 DF, p-value: &lt; 2.2e-16 7.4 処置の結果変数は操作変数になりうるか？ tidy_dag_2 &lt;- ggdag::dagify( Y ~ D + U, D ~ U, Z ~ D, exposure = &quot;D&quot;, # 処置変数（暴露 [exposure]） を指定 outcome = &quot;Y&quot; , # 結果変数を指定 latent = &quot;U&quot;, # 未観測（潜在[latent]）変数を指定 coords = list(x = c(Z = 0, D = 1, Y = 3, U = 2), y = c(Z = 0, D = 0, Y = 0, U = 1)) ) %&gt;% ggdag::tidy_dagitty() ggdag::ggdag(tidy_dag_2) + theme_dag() u&lt;-rnorm(1000) d&lt;-1+3*u+rnorm(1000) z&lt;-2*d+rnorm(1000) y&lt;-0.5*d+0.8*u+rnorm(1000) dt&lt;-tibble(u,z,d,y) lm(y~d,data=dt) %&gt;%summary #biased ## ## Call: ## lm(formula = y ~ d, data = dt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.6746 -0.6928 -0.0157 0.6955 3.0680 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.25310 0.03456 -7.323 4.99e-13 *** ## d 0.73716 0.01044 70.634 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.042 on 998 degrees of freedom ## Multiple R-squared: 0.8333, Adjusted R-squared: 0.8331 ## F-statistic: 4989 on 1 and 998 DF, p-value: &lt; 2.2e-16 lm(y~d+z,data=dt) %&gt;%summary #biased ## ## Call: ## lm(formula = y ~ d + z, data = dt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.6799 -0.6909 -0.0167 0.7007 3.0706 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.252989 0.034582 -7.316 5.26e-13 *** ## d 0.753898 0.066978 11.256 &lt; 2e-16 *** ## z -0.008351 0.033008 -0.253 0.8 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.043 on 997 degrees of freedom ## Multiple R-squared: 0.8333, Adjusted R-squared: 0.833 ## F-statistic: 2492 on 2 and 997 DF, p-value: &lt; 2.2e-16 #install.packages(&quot;estimatr&quot;) library(estimatr) iv_robust(y ~ d | z, data = dt, se_type = &quot;classical&quot;) %&gt;%summary ## ## Call: ## iv_robust(formula = y ~ d | z, data = dt, se_type = &quot;classical&quot;) ## ## Standard error type: classical ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF ## (Intercept) -0.2527 0.03460 -7.303 5.764e-13 -0.3206 -0.1848 998 ## d 0.7367 0.01057 69.731 0.000e+00 0.7160 0.7575 998 ## ## Multiple R-squared: 0.8333 , Adjusted R-squared: 0.8331 ## F-statistic: 4862 on 1 and 998 DF, p-value: &lt; 2.2e-16 操作変数はUと独立でなければならない。そのため、上の例はダメ。下の例ならOK。下の例ではAもZも操作変数となる。（Aが観測できるならAでよいが、観測できなくてもZを使える） tidy_dag_2 &lt;- ggdag::dagify( Y ~ D + U, D ~ U+A, Z ~ A, exposure = &quot;D&quot;, # 処置変数（暴露 [exposure]） を指定 outcome = &quot;Y&quot; , # 結果変数を指定 latent = &quot;U&quot;, # 未観測（潜在[latent]）変数を指定 coords = list(x = c(Z = 1, D = 1, Y = 3, U = 2,A=0), y = c(Z = -0.5, D = 0, Y = 0, U = 1,A=0)) ) %&gt;% ggdag::tidy_dagitty() ggdag::ggdag(tidy_dag_2) + theme_dag() u&lt;-rnorm(1000) a&lt;-rnorm(1000) d&lt;-1+2*a+3*u+rnorm(1000) y&lt;-0.5*d+0.8*u+rnorm(1000) z&lt;-1+a+rnorm(1000) dt&lt;-tibble(u,z,d,y,a) lm(y~d,data=dt) %&gt;%summary #biased ## ## Call: ## lm(formula = y ~ d, data = dt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.2848 -0.7733 0.0242 0.7822 3.1403 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.234727 0.035850 -6.547 9.35e-11 *** ## d 0.670178 0.009602 69.794 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.103 on 998 degrees of freedom ## Multiple R-squared: 0.83, Adjusted R-squared: 0.8298 ## F-statistic: 4871 on 1 and 998 DF, p-value: &lt; 2.2e-16 lm(y~d+z,data=dt) %&gt;%summary #biased ## ## Call: ## lm(formula = y ~ d + z, data = dt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.08517 -0.76739 0.02363 0.77817 3.12588 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.10115 0.04175 -2.423 0.0156 * ## d 0.69103 0.01007 68.654 &lt; 2e-16 *** ## z -0.15857 0.02656 -5.970 3.3e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.084 on 997 degrees of freedom ## Multiple R-squared: 0.8358, Adjusted R-squared: 0.8355 ## F-statistic: 2538 on 2 and 997 DF, p-value: &lt; 2.2e-16 library(estimatr) #unbiased iv_robust(y ~ d | z, data = dt, se_type = &quot;classical&quot;) %&gt;%summary ## ## Call: ## iv_robust(formula = y ~ d | z, data = dt, se_type = &quot;classical&quot;) ## ## Standard error type: classical ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF ## (Intercept) -0.1024 0.04738 -2.162 3.089e-02 -0.1954 -0.009442 998 ## d 0.5179 0.03096 16.730 1.428e-55 0.4572 0.578651 998 ## ## Multiple R-squared: 0.7871 , Adjusted R-squared: 0.7869 ## F-statistic: 279.9 on 1 and 998 DF, p-value: &lt; 2.2e-16 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
